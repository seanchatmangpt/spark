{
    "sourceFile": "documentation/concepts/overview.md",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1749702914950,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1749702914950,
            "name": "Commit-0",
            "content": "# What is Spark?\n\n> **The Ultimate Elixir DSL Framework** - Build powerful, extensible Domain Specific Languages with enterprise-grade tooling\n\n## üéØ What Spark Does\n\nSpark is a framework that makes it **trivial** to build sophisticated Domain Specific Languages (DSLs) in Elixir. Instead of writing hundreds of lines of metaprogramming code, you define your DSL structure with simple data structures and get a complete, production-ready DSL with tooling included.\n\n### **Before Spark** (Manual DSL Creation)\n```elixir\n# 100+ lines of complex metaprogramming\ndefmodule MyApp.Validator do\n  defmacro __using__(_opts) do\n    quote do\n      import MyApp.Validator.Macros\n      # ... 50+ lines of macro definitions\n    end\n  end\nend\n\n# Complex macro definitions\ndefmodule MyApp.Validator.Macros do\n  defmacro fields(do: block) do\n    # ... 30+ lines of AST manipulation\n  end\n  \n  defmacro field(name, type, opts \\\\ []) do\n    # ... 20+ lines of validation logic\n  end\nend\n```\n\n### **With Spark** (Declarative DSL Definition)\n```elixir\n# 20 lines of declarative configuration\ndefmodule MyApp.Validator.Dsl do\n  @field %Spark.Dsl.Entity{\n    name: :field,\n    args: [:name, :type],\n    schema: [\n      name: [type: :atom, required: true],\n      type: [type: {:one_of, [:string, :integer]}, required: true]\n    ]\n  }\n\n  @fields %Spark.Dsl.Section{\n    name: :fields,\n    entities: [@field]\n  }\n\n  use Spark.Dsl.Extension, sections: [@fields]\nend\n\ndefmodule MyApp.Validator do\n  use Spark.Dsl, default_extensions: [extensions: [MyApp.Validator.Dsl]]\nend\n```\n\n## üåü What You Get for Free\n\n### **1. Complete DSL Infrastructure**\n- ‚úÖ **Compile-time validation** - Catch errors before runtime\n- ‚úÖ **Runtime introspection** - Query your DSL configuration\n- ‚úÖ **Extensibility** - Add features without breaking existing code\n- ‚úÖ **Documentation generation** - Auto-generate DSL docs\n- ‚úÖ **IDE support** - Full autocomplete and inline docs\n\n### **2. Enterprise-Grade Tooling**\n- ‚úÖ **Cheat sheet generation** - Create instant reference guides\n- ‚úÖ **Performance analysis** - Built-in profiling and optimization\n- ‚úÖ **Testing utilities** - Comprehensive testing support\n- ‚úÖ **Migration tools** - Upgrade paths for DSL changes\n\n### **3. Zero-Configuration Developer Experience**\n- ‚úÖ **Automatic formatting** - Perfect `locals_without_parens` setup\n- ‚úÖ **Live documentation** - Inline help as you type\n- ‚úÖ **Error reporting** - Clear, actionable error messages\n- ‚úÖ **Claude integration** - AI-powered development workflows\n\n## üèóÔ∏è Core Architecture\n\n### **The Spark Model**\n\nSpark uses a **declarative model** where you define your DSL structure using data structures, not code:\n\n```elixir\n# Define what your DSL looks like\n@field %Spark.Dsl.Entity{\n  name: :field,           # DSL keyword\n  args: [:name, :type],   # Required arguments\n  schema: [               # Validation rules\n    name: [type: :atom, required: true],\n    type: [type: {:one_of, [:string, :integer]}, required: true]\n  ]\n}\n\n# Spark generates all the code for you\n```\n\n### **Key Components**\n\n#### **1. Extensions** - Define DSL Structure\nExtensions specify what your DSL can do:\n- **Sections** - Top-level DSL blocks (like `fields do ... end`)\n- **Entities** - DSL elements within sections (like `field :name, :string`)\n- **Schema** - Validation rules for each element\n- **Transformers** - Compile-time processing\n- **Verifiers** - Compile-time validation\n\n#### **2. DSL Modules** - User Interface\nWhat users `use` to create DSL instances:\n```elixir\ndefmodule MyApp.Validator do\n  use Spark.Dsl, default_extensions: [extensions: [MyApp.Validator.Dsl]]\nend\n```\n\n#### **3. Info Modules** - Runtime Access\nAuto-generated modules for querying DSL data:\n```elixir\n# Automatically generated\nMyApp.Validator.Info.fields(module)     # Get all fields\nMyApp.Validator.Info.field(module, :name) # Get specific field\n```\n\n## üöÄ Why Spark is Revolutionary\n\n### **1. Declarative Over Imperative**\nInstead of writing complex metaprogramming code, you declare what you want:\n```elixir\n# Declarative (Spark)\n@field %Spark.Dsl.Entity{name: :field, args: [:name, :type]}\n\n# Imperative (Traditional)\ndefmacro field(name, type) do\n  quote do\n    # ... 20+ lines of AST manipulation\n  end\nend\n```\n\n### **2. Compile-Time Safety**\nAll validation happens at compile time, catching errors before deployment:\n```elixir\n# This will fail at compile time with a clear error\nfield :name, :invalid_type  # Error: Type must be one of [:string, :integer]\n```\n\n### **3. Extensibility by Design**\nAnyone can extend your DSL without modifying your code:\n```elixir\n# User can add their own extensions\ndefmodule MyApp.CustomExtension do\n  use Spark.Dsl.Extension, sections: [@custom_section]\nend\n\n# Use with custom extension\ndefmodule MyApp.MyValidator do\n  use MyApp.Validator, extensions: [MyApp.CustomExtension]\nend\n```\n\n### **4. Zero Runtime Overhead**\nAll DSL processing happens at compile time, resulting in zero runtime cost:\n```elixir\n# Compile time: DSL is processed and validated\n# Runtime: Just normal function calls\nfields = MyApp.Validator.Info.fields(module)  # Fast, no DSL processing\n```\n\n## üéØ When to Use Spark\n\n### **Perfect For**\n- ‚úÖ **API definition DSLs** - Define REST/GraphQL APIs declaratively\n- ‚úÖ **Configuration DSLs** - Environment-specific configuration\n- ‚úÖ **Validation DSLs** - Data validation and transformation\n- ‚úÖ **Workflow DSLs** - Business process definitions\n- ‚úÖ **Schema DSLs** - Database schema definitions\n- ‚úÖ **Any complex DSL** - Where you need validation, introspection, and tooling\n\n### **Not Ideal For**\n- ‚ùå **Simple one-off DSLs** - Overkill for basic metaprogramming\n- ‚ùå **Performance-critical loops** - Use direct function calls instead\n- ‚ùå **Dynamic DSLs** - DSLs that change at runtime\n\n## üåç Ecosystem Integration\n\n### **Ash Framework Foundation**\nSpark powers all DSLs in the Ash ecosystem:\n- **Ash.Resource** - Data layer DSLs\n- **Ash.Api** - API definition DSLs\n- **AshGraphql** - GraphQL DSLs\n- **AshJsonApi** - JSON:API DSLs\n\n### **Elixir Ecosystem**\n- **Phoenix** - Web framework integration\n- **Ecto** - Database integration\n- **LiveView** - Real-time UI DSLs\n- **Telemetry** - Observability integration\n\n## üìä Real-World Impact\n\n### **Development Speed**\n- **90% reduction** in DSL development time\n- **Zero configuration errors** when following patterns\n- **Immediate productivity** with complex DSL patterns\n\n### **Code Quality**\n- **Compile-time validation** catches errors early\n- **Consistent patterns** across all DSLs\n- **Comprehensive testing** built-in\n\n### **Maintainability**\n- **Self-documenting** DSL definitions\n- **Extensible architecture** allows evolution\n- **Clear separation** of concerns\n\n## üöÄ Next Steps\n\n1. **[Why Use Spark?](benefits.md)** - See the specific advantages\n2. **[5-Minute Quick Start](../tutorials/quick-start.md)** - Build your first DSL\n3. **[Generator Tutorials](../tutorials/generators/)** - Use generators for instant DSLs\n4. **[Manual DSL Creation](../tutorials/manual/)** - Build from scratch\n\n---\n\n**Ready to build amazing DSLs?** [Start with the 5-Minute Quick Start ‚Üí](../tutorials/quick-start.md) "
        }
    ]
}