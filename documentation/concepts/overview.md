# What is Spark?

> **The Ultimate Elixir DSL Framework** - Build powerful, extensible Domain Specific Languages with enterprise-grade tooling

## üéØ What Spark Does

Spark is a framework that makes it **trivial** to build sophisticated Domain Specific Languages (DSLs) in Elixir. Instead of writing hundreds of lines of metaprogramming code, you define your DSL structure with simple data structures and get a complete, production-ready DSL with tooling included.

### **Before Spark** (Manual DSL Creation)
```elixir
# 100+ lines of complex metaprogramming
defmodule MyApp.Validator do
  defmacro __using__(_opts) do
    quote do
      import MyApp.Validator.Macros
      # ... 50+ lines of macro definitions
    end
  end
end

# Complex macro definitions
defmodule MyApp.Validator.Macros do
  defmacro fields(do: block) do
    # ... 30+ lines of AST manipulation
  end
  
  defmacro field(name, type, opts \\ []) do
    # ... 20+ lines of validation logic
  end
end
```

### **With Spark** (Declarative DSL Definition)
```elixir
# 20 lines of declarative configuration
defmodule MyApp.Validator.Dsl do
  @field %Spark.Dsl.Entity{
    name: :field,
    args: [:name, :type],
    schema: [
      name: [type: :atom, required: true],
      type: [type: {:one_of, [:string, :integer]}, required: true]
    ]
  }

  @fields %Spark.Dsl.Section{
    name: :fields,
    entities: [@field]
  }

  use Spark.Dsl.Extension, sections: [@fields]
end

defmodule MyApp.Validator do
  use Spark.Dsl, default_extensions: [extensions: [MyApp.Validator.Dsl]]
end
```

## üåü What You Get for Free

### **1. Complete DSL Infrastructure**
- ‚úÖ **Compile-time validation** - Catch errors before runtime
- ‚úÖ **Runtime introspection** - Query your DSL configuration
- ‚úÖ **Extensibility** - Add features without breaking existing code
- ‚úÖ **Documentation generation** - Auto-generate DSL docs
- ‚úÖ **IDE support** - Full autocomplete and inline docs

### **2. Enterprise-Grade Tooling**
- ‚úÖ **Cheat sheet generation** - Create instant reference guides
- ‚úÖ **Performance analysis** - Built-in profiling and optimization
- ‚úÖ **Testing utilities** - Comprehensive testing support
- ‚úÖ **Migration tools** - Upgrade paths for DSL changes

### **3. Zero-Configuration Developer Experience**
- ‚úÖ **Automatic formatting** - Perfect `locals_without_parens` setup
- ‚úÖ **Live documentation** - Inline help as you type
- ‚úÖ **Error reporting** - Clear, actionable error messages
- ‚úÖ **Claude integration** - AI-powered development workflows

## üèóÔ∏è Core Architecture

### **The Spark Model**

Spark uses a **declarative model** where you define your DSL structure using data structures, not code:

```elixir
# Define what your DSL looks like
@field %Spark.Dsl.Entity{
  name: :field,           # DSL keyword
  args: [:name, :type],   # Required arguments
  schema: [               # Validation rules
    name: [type: :atom, required: true],
    type: [type: {:one_of, [:string, :integer]}, required: true]
  ]
}

# Spark generates all the code for you
```

### **Key Components**

#### **1. Extensions** - Define DSL Structure
Extensions specify what your DSL can do:
- **Sections** - Top-level DSL blocks (like `fields do ... end`)
- **Entities** - DSL elements within sections (like `field :name, :string`)
- **Schema** - Validation rules for each element
- **Transformers** - Compile-time processing
- **Verifiers** - Compile-time validation

#### **2. DSL Modules** - User Interface
What users `use` to create DSL instances:
```elixir
defmodule MyApp.Validator do
  use Spark.Dsl, default_extensions: [extensions: [MyApp.Validator.Dsl]]
end
```

#### **3. Info Modules** - Runtime Access
Auto-generated modules for querying DSL data:
```elixir
# Automatically generated
MyApp.Validator.Info.fields(module)     # Get all fields
MyApp.Validator.Info.field(module, :name) # Get specific field
```

## üöÄ Why Spark is Revolutionary

### **1. Declarative Over Imperative**
Instead of writing complex metaprogramming code, you declare what you want:
```elixir
# Declarative (Spark)
@field %Spark.Dsl.Entity{name: :field, args: [:name, :type]}

# Imperative (Traditional)
defmacro field(name, type) do
  quote do
    # ... 20+ lines of AST manipulation
  end
end
```

### **2. Compile-Time Safety**
All validation happens at compile time, catching errors before deployment:
```elixir
# This will fail at compile time with a clear error
field :name, :invalid_type  # Error: Type must be one of [:string, :integer]
```

### **3. Extensibility by Design**
Anyone can extend your DSL without modifying your code:
```elixir
# User can add their own extensions
defmodule MyApp.CustomExtension do
  use Spark.Dsl.Extension, sections: [@custom_section]
end

# Use with custom extension
defmodule MyApp.MyValidator do
  use MyApp.Validator, extensions: [MyApp.CustomExtension]
end
```

### **4. Zero Runtime Overhead**
All DSL processing happens at compile time, resulting in zero runtime cost:
```elixir
# Compile time: DSL is processed and validated
# Runtime: Just normal function calls
fields = MyApp.Validator.Info.fields(module)  # Fast, no DSL processing
```

## üéØ When to Use Spark

### **Perfect For**
- ‚úÖ **API definition DSLs** - Define REST/GraphQL APIs declaratively
- ‚úÖ **Configuration DSLs** - Environment-specific configuration
- ‚úÖ **Validation DSLs** - Data validation and transformation
- ‚úÖ **Workflow DSLs** - Business process definitions
- ‚úÖ **Schema DSLs** - Database schema definitions
- ‚úÖ **Any complex DSL** - Where you need validation, introspection, and tooling

### **Not Ideal For**
- ‚ùå **Simple one-off DSLs** - Overkill for basic metaprogramming
- ‚ùå **Performance-critical loops** - Use direct function calls instead
- ‚ùå **Dynamic DSLs** - DSLs that change at runtime

## üåç Ecosystem Integration

### **Ash Framework Foundation**
Spark powers all DSLs in the Ash ecosystem:
- **Ash.Resource** - Data layer DSLs
- **Ash.Api** - API definition DSLs
- **AshGraphql** - GraphQL DSLs
- **AshJsonApi** - JSON:API DSLs

### **Elixir Ecosystem**
- **Phoenix** - Web framework integration
- **Ecto** - Database integration
- **LiveView** - Real-time UI DSLs
- **Telemetry** - Observability integration

## üìä Real-World Impact

### **Development Speed**
- **90% reduction** in DSL development time
- **Zero configuration errors** when following patterns
- **Immediate productivity** with complex DSL patterns

### **Code Quality**
- **Compile-time validation** catches errors early
- **Consistent patterns** across all DSLs
- **Comprehensive testing** built-in

### **Maintainability**
- **Self-documenting** DSL definitions
- **Extensible architecture** allows evolution
- **Clear separation** of concerns

## üöÄ Next Steps

1. **[Why Use Spark?](benefits.md)** - See the specific advantages
2. **[5-Minute Quick Start](../tutorials/quick-start.md)** - Build your first DSL
3. **[Generator Tutorials](../tutorials/generators/)** - Use generators for instant DSLs
4. **[Manual DSL Creation](../tutorials/manual/)** - Build from scratch

---

**Ready to build amazing DSLs?** [Start with the 5-Minute Quick Start ‚Üí](../tutorials/quick-start.md) 